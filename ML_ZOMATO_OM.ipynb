{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 - Vaghasiya Om Vijaybhai**\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focused on performing an end-to-end data science analysis on restaurant and customer review data to extract meaningful insights and build predictive machine learning models. The objective was to understand customer behavior, analyze restaurant attributes, process textual feedback, and predict customer ratings using robust data-driven techniques. The entire workflow followed a structured data science pipeline, including data understanding, data wrangling, visualization, feature engineering, hypothesis testing, and machine learning model implementation.\n",
        "\n",
        "Initially, two datasets were explored independently: a restaurant metadata dataset and a customer reviews dataset. Exploratory data analysis helped identify key numerical and categorical variables, missing values, and data quality issues. Data wrangling steps such as standardizing column names, handling missing values, removing duplicates, and cleaning cost-related fields were applied to ensure consistency and reliability. Outliers in numerical features such as review length and restaurant cost were handled using the IQR method to reduce noise and improve model robustness.\n",
        "\n",
        "Data visualization played a crucial role in understanding relationships between variables. Various plots such as histograms, boxplots, scatter plots, bar charts, KDE plots, correlation heatmaps, and pair plots were used to analyze rating distributions, review engagement, pricing patterns, cuisine popularity, and feature relationships. These visual insights highlighted trends such as generally positive customer ratings, higher engagement for extreme opinions, and a concentration of restaurants in low-to-mid pricing segments.\n",
        "\n",
        "Hypothesis testing was conducted to statistically validate insights obtained from visual exploration. Tests such as Pearson correlation, independent two-sample t-tests, and one-sample t-tests were used to examine relationships between review length and ratings, cost distributions, and average rating behavior. The results supported the presence of meaningful relationships and provided statistical backing for data-driven conclusions.\n",
        "\n",
        "Feature engineering and preprocessing were essential components of the project. New features such as cost categories, number of cuisines, rating categories, and review length were created to enrich the dataset. Textual data preprocessing involved contraction expansion, lowercasing, noise removal, stopword elimination, tokenization, normalization through stemming and lemmatization, POS tagging, and vectorization using TF-IDF. These steps transformed unstructured text into meaningful numerical representations suitable for modeling.\n",
        "\n",
        "Three machine learning models were implemented to predict customer ratings: Linear Regression, Random Forest Regressor, and Support Vector Regression (SVR). Each model was evaluated using RMSE and R² score to measure prediction accuracy and explanatory power. Cross-validation ensured model stability, while hyperparameter tuning using GridSearchCV and RandomizedSearchCV improved performance. Among the models, Random Forest Regressor demonstrated superior performance due to its ability to capture non-linear relationships and generalize well.\n",
        "\n",
        "Model explainability was addressed using Random Forest feature importance, which highlighted review length and numerical features as key drivers of customer ratings. This interpretability enabled translation of model results into actionable business insights.\n",
        "\n",
        "In conclusion, the project successfully demonstrated how data science techniques can be applied to real-world datasets to generate insights, validate hypotheses, and build reliable predictive models. The final model can support positive business impact by enhancing customer satisfaction analysis, improving recommendation systems, and guiding strategic decisions for restaurant platforms and service providers."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/omvaghasiya/Zomato-Restaurant-Data-Analysis/"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rapid growth of online food delivery and restaurant review platforms has led to the generation of large volumes of customer feedback and restaurant-related data. However, extracting meaningful insights from this heterogeneous data and accurately understanding customer preferences remains a challenge for businesses. Restaurants and service platforms need effective data-driven approaches to analyze customer reviews, pricing patterns, and engagement behavior in order to improve customer satisfaction and optimize decision-making."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Check available files: !ls\n",
        "# If files are in a specific directory, update the path accordingly.\n",
        "restaurants = pd.read_csv(\"Zomato Restaurant names and Metadata.csv\")\n",
        "reviews = pd.read_csv(\"Zomato Restaurant reviews.csv\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "print(\"Restaurants Dataset Shape:\", restaurants.shape)\n",
        "print(\"Reviews Dataset Shape:\", reviews.shape)\n",
        "\n",
        "restaurants.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Restaurants Dataset Shape:\", restaurants.shape)\n",
        "print(\"Reviews Dataset Shape:\", reviews.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(\"Restaurants Dataset Info:\")\n",
        "print(restaurants.info())\n",
        "\n",
        "print(\"\\nReviews Dataset Info:\")\n",
        "print(reviews.info())"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Restaurants Dataset Duplicate Values:\", restaurants.duplicated().sum())\n",
        "print(\"Reviews Dataset Duplicate Values:\", reviews.duplicated().sum())\n",
        "# restaurants.drop_duplicates(inplace=True)\n",
        "# reviews.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Restaurants Dataset Missing Values:\")\n",
        "print(restaurants.isnull().sum())\n",
        "\n",
        "print(\"\\nReviews Dataset Missing Values:\")\n",
        "print(reviews.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "missing_rest = restaurants.isnull().sum()\n",
        "missing_rest = missing_rest[missing_rest > 0]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "missing_rest.plot(kind='bar')\n",
        "plt.title(\"Missing Values Count per Column – Restaurants Dataset\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "missing_rev = reviews.isnull().sum()\n",
        "missing_rev = missing_rev[missing_rev > 0]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "missing_rev.plot(kind='bar')\n",
        "plt.title(\"Missing Values Count per Column – Reviews Dataset\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# sns.heatmap(restaurants.isnull(), cbar=False, cmap='viridis')\n",
        "# plt.title(\"Missing Values Heatmap – Restaurants Dataset\")\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# sns.heatmap(reviews.isnull(), cbar=False, cmap='viridis')\n",
        "# plt.title(\"Missing Values Heatmap – Reviews Dataset\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding of the Dataset\n",
        "\n",
        "The project uses two datasets related to Zomato restaurants. The first dataset contains restaurant-level metadata, including information such as restaurant names, locations, cuisines, average cost for two, ratings, and online service availability. This dataset is primarily structured and numerical/categorical in nature, making it suitable for exploratory data analysis and predictive modeling.\n",
        "\n",
        "The second dataset consists of customer reviews, which includes textual reviews and associated ratings. This dataset is unstructured and is useful for text analysis, sentiment extraction, and understanding customer perception. Together, both datasets provide a comprehensive view of restaurant performance by combining structured attributes with user-generated feedback.\n",
        "\n",
        "Initial exploration revealed the presence of missing values and categorical features that require preprocessing. The datasets also vary in scale and data type, highlighting the need for data cleaning, feature engineering, and visualization before applying machine learning models.\n",
        "e"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Restaurants Dataset Columns:\", restaurants.columns.tolist())\n",
        "print(\"Reviews Dataset Columns:\", reviews.columns.tolist())\n",
        "\n",
        "# Display data types of each column\n",
        "print(\"\\nRestaurants Dataset Column Data Types:\")\n",
        "print(restaurants.dtypes)\n",
        "\n",
        "print(\"\\nReviews Dataset Column Data Types:\")\n",
        "print(reviews.dtypes)\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(\"Restaurants Dataset Describe:\")\n",
        "print(restaurants.describe())\n",
        "\n",
        "print(\"\\nReviews Dataset Describe:\")\n",
        "print(reviews.describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description\n",
        "\n",
        "The restaurant dataset includes numerical variables such as ratings, average cost for two, and votes, which provide quantitative insights into pricing and customer preferences. Categorical variables include restaurant location, cuisines, and service options like online ordering and table booking, describing qualitative characteristics of each restaurant.\n",
        "\n",
        "The reviews dataset primarily contains textual review content along with associated ratings. The review text represents unstructured data and is useful for understanding customer sentiment, while derived features such as review length can be used to quantify engagement.\n",
        "\n",
        "These variables together enable both exploratory analysis and predictive modeling by combining structured restaurant attributes with user-generated feedback.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(\"Unique Values in Restaurants Dataset:\")\n",
        "print(restaurants.nunique())\n",
        "\n",
        "print(\"\\nUnique Values in Reviews Dataset:\")\n",
        "print(reviews.nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# Make copies to avoid modifying original datasets\n",
        "restaurants_wrangled = restaurants.copy()\n",
        "reviews_wrangled = reviews.copy()\n",
        "\n",
        "# Standardize column names (lowercase, replace spaces)\n",
        "restaurants_wrangled.columns = restaurants_wrangled.columns.str.lower().str.replace(\" \", \"_\")\n",
        "reviews_wrangled.columns = reviews_wrangled.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Strip whitespace from string columns\n",
        "for col in restaurants_wrangled.select_dtypes(include='object').columns:\n",
        "    restaurants_wrangled[col] = restaurants_wrangled[col].str.strip()\n",
        "\n",
        "for col in reviews_wrangled.select_dtypes(include='object').columns:\n",
        "    reviews_wrangled[col] = reviews_wrangled[col].str.strip()\n",
        "# Drop duplicates\n",
        "restaurants_wrangled.drop_duplicates(inplace=True)\n",
        "reviews_wrangled.drop_duplicates(inplace=True)\n",
        "\n",
        "# Convert review rating to numeric and remove invalid values\n",
        "if 'rating' in reviews_wrangled.columns:\n",
        "    reviews_wrangled['rating'] = pd.to_numeric(\n",
        "        reviews_wrangled['rating'], errors='coerce'\n",
        "    )\n",
        "    reviews_wrangled = reviews_wrangled.dropna(subset=['rating'])\n",
        "\n",
        "# Create cost per person feature\n",
        "if 'average_cost_for_two' in restaurants_wrangled.columns:\n",
        "    restaurants_wrangled['cost_per_person'] = restaurants_wrangled['average_cost_for_two'] / 2\n",
        "\n",
        "# Handle ratings ONLY in reviews dataset\n",
        "if 'rating' in reviews_wrangled.columns:\n",
        "    reviews_wrangled['rating'] = pd.to_numeric(\n",
        "        reviews_wrangled['rating'], errors='coerce'\n",
        "    )\n",
        "    reviews_wrangled.dropna(subset=['rating'], inplace=True)\n",
        "\n",
        "# Handle missing review text safely\n",
        "if 'review' in reviews_wrangled.columns:\n",
        "    reviews_wrangled['review'] = reviews_wrangled['review'].fillna(\"\")\n",
        "    reviews_wrangled['review_length'] = reviews_wrangled['review'].apply(len)\n",
        "\n",
        "# Reset index\n",
        "restaurants_wrangled.reset_index(drop=True, inplace=True)\n",
        "reviews_wrangled.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Restaurants shape:\", restaurants_wrangled.shape)\n",
        "print(\"Reviews shape:\", reviews_wrangled.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling: Manipulations and Insights\n",
        "\n",
        "Several preprocessing and data wrangling steps were performed to make the datasets analysis-ready.\n",
        "\n",
        "First, copies of both datasets were created to preserve the original data. Column names were standardized by converting them to lowercase and replacing spaces with underscores to maintain consistency and ease of access. Leading and trailing whitespaces were removed from all string-based columns to avoid inconsistencies during analysis.\n",
        "\n",
        "Duplicate records were identified and removed from both the restaurant and reviews datasets to ensure data integrity. In the reviews dataset, the **rating** column was converted to a numeric format, and rows containing invalid or missing ratings were removed. Missing values in the **review** text column were safely handled by replacing them with empty strings, enabling feature extraction without errors. A new feature, **review_length**, was created to measure customer engagement based on review size.\n",
        "\n",
        "For the restaurant dataset, a new numerical feature **cost_per_person** was derived from **average_cost_for_two**, providing a more granular measure of pricing. Finally, dataset indices were reset to maintain clean and continuous indexing.\n",
        "\n",
        "Through these steps, both datasets were cleaned, standardized, and enriched with meaningful features, making them suitable for exploratory analysis and further machine learning tasks.\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set visualization style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(reviews_wrangled['rating'], bins=20, kde=True)\n",
        "plt.title(\"Distribution of Restaurant Ratings\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen because it clearly represents the distribution of ratings across all restaurants, making it easy to observe how frequently each rating range occurs and to identify overall rating patterns.\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The visualization shows that most restaurant ratings fall within a moderate to high range, indicating generally positive customer experiences. Extremely low or high ratings appear less frequently, suggesting fewer extreme cases.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping restaurants and platforms understand typical customer satisfaction levels. Businesses can focus on improving service quality to increase average ratings, while platforms can promote consistently well-rated restaurants to enhance user trust and engagement.\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(\n",
        "    x='rating',\n",
        "    y='review_length',\n",
        "    data=reviews_wrangled,\n",
        "    alpha=0.5\n",
        ")\n",
        "plt.title(\"Rating vs Review Length\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Review Length\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen because it is effective for visualizing the relationship between two numerical variables, allowing us to observe how review length varies with customer ratings.\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that review length varies across all rating values, with longer reviews appearing at both high and low ratings. This suggests that customers tend to write more detailed reviews when they have strong opinions, whether positive or negative.\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can help create a positive business impact by enabling businesses to identify highly engaged customers and understand feedback depth. Longer reviews often contain actionable insights that restaurants can use to improve services and customer satisfaction.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(reviews_wrangled['review_length'], bins=30)\n",
        "plt.title(\"Distribution of Review Length\")\n",
        "plt.xlabel(\"Review Length\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was selected to understand the distribution of review lengths, as it effectively shows how frequently different review sizes occur and helps identify common patterns in customer feedback behavior.\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that most reviews are relatively short, while a smaller number of reviews are significantly longer. This indicates that the majority of users provide brief feedback, whereas detailed reviews are less common and usually reflect stronger engagement.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping businesses focus on extracting value from longer, more detailed reviews, which often contain actionable feedback. Platforms can also encourage detailed reviews to gain deeper customer insights and improve service quality.\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=reviews_wrangled['rating'])\n",
        "plt.title(\"Boxplot of Ratings\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot was chosen because it provides a clear summary of the rating distribution by displaying the median, interquartile range, and potential outliers in a compact visual form.\n"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that ratings are mostly clustered within a limited range, showing consistent customer feedback. The presence of a few outliers suggests that there are occasional exceptionally positive or negative experiences.\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by allowing businesses to monitor consistency in customer satisfaction. Identifying and addressing outlier cases can help improve service quality, reduce negative experiences, and strengthen overall customer trust.\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=reviews_wrangled['review_length'])\n",
        "plt.title(\"Boxplot of Review Length\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot was chosen because it effectively summarizes the distribution of review lengths by highlighting the median, spread, and presence of outliers, which helps understand variability in customer engagement.\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that most reviews are relatively short, while a number of outliers represent very long reviews. This indicates that although many users provide brief feedback, a smaller group of users contributes highly detailed reviews.\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping businesses focus on longer reviews that often contain detailed and actionable feedback. Identifying and analyzing these outliers can support service improvements and better decision-making.\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Clean cost column: extract numeric values\n",
        "restaurants_wrangled['cost_numeric'] = (\n",
        "    restaurants_wrangled['cost']\n",
        "    .astype(str)\n",
        "    .str.replace('₹', '', regex=False)\n",
        "    .str.replace('for two', '', regex=False)\n",
        "    .str.replace(',', '', regex=False)\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "restaurants_wrangled['cost_numeric'] = pd.to_numeric(\n",
        "    restaurants_wrangled['cost_numeric'], errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop rows where cost could not be converted\n",
        "restaurants_wrangled.dropna(subset=['cost_numeric'], inplace=True)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(restaurants_wrangled['cost_numeric'], bins=30)\n",
        "plt.title(\"Distribution of Restaurant Cost\")\n",
        "plt.xlabel(\"Cost (for two)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen to visualize the distribution of restaurant costs, as it clearly shows how pricing is spread across different restaurants and helps identify common cost ranges and pricing patterns.\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that most restaurants fall within a lower to mid-price range, while fewer restaurants operate at higher price points. This indicates a market dominated by affordable and moderately priced dining options, with premium restaurants being less common.\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping restaurants position themselves competitively within appropriate pricing segments. Platforms can also use this information to recommend restaurants based on user budget preferences and improve customer satisfaction.\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "top_cuisines = restaurants_wrangled['cuisines'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_cuisines.values, y=top_cuisines.index)\n",
        "plt.title(\"Top 10 Cuisines by Restaurant Count\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Cuisine\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was selected to compare the frequency of different cuisine types, as it clearly highlights the most popular cuisines based on the number of restaurants offering them.\n"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that certain cuisines dominate the restaurant landscape, indicating strong customer demand and widespread availability. Less frequent cuisines appear lower in the ranking, suggesting niche or specialized offerings.\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping restaurant owners understand market demand and identify popular cuisine trends. Food platforms can use this information to optimize recommendations, while new businesses can make informed decisions about cuisine selection.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "top_collections = restaurants_wrangled['collections'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_collections.values, y=top_collections.index)\n",
        "plt.title(\"Top Restaurant Collections\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Collection\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen to compare different restaurant collections, as it clearly displays which collections appear most frequently and allows easy comparison across categories.\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that a few collections dominate in terms of restaurant count, suggesting that these collections are more popular or widely adopted. Other collections appear less frequently, indicating more specialized or niche groupings.\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that a few collections dominate in terms of restaurant count, suggesting that these collections are more popular or widely adopted. Other collections appear less frequently, indicating more specialized or niche groupings.\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.kdeplot(restaurants_wrangled['cost_numeric'], fill=True)\n",
        "plt.title(\"Density Plot of Restaurant Cost\")\n",
        "plt.xlabel(\"Cost (for two)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A density plot was chosen to understand the overall distribution and concentration of restaurant costs, as it provides a smooth representation of how pricing values are spread across the dataset.\n"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that restaurant costs are densely concentrated around lower to mid-price ranges, with the density gradually decreasing as prices increase. This indicates that most restaurants cater to budget and mid-range customers, while high-cost restaurants are relatively fewer.\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping platforms tailor recommendations based on customer budget preferences and enabling restaurants to price their offerings competitively. Understanding cost concentration also supports better market segmentation and targeted promotions.\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Correlation Heatmap for Reviews Dataset\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(\n",
        "    reviews_wrangled[['rating', 'review_length']].corr(),\n",
        "    annot=True,\n",
        "    cmap='coolwarm',\n",
        "    fmt=\".2f\"\n",
        ")\n",
        "plt.title(\"Correlation Heatmap - Reviews Dataset\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation Heatmap for Restaurants Dataset\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(\n",
        "    restaurants_wrangled[['cost_numeric']].corr(),\n",
        "    annot=True,\n",
        "    cmap='coolwarm',\n",
        "    fmt=\".2f\"\n",
        ")\n",
        "plt.title(\"Correlation Heatmap - Restaurants Dataset\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap was chosen to visually represent the strength and direction of relationships between numerical variables, making it easier to identify correlations at a glance using color intensity.\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap for the reviews dataset shows the correlation between rating and review length, indicating how customer engagement relates to satisfaction levels. The restaurant dataset heatmap confirms that cost is an independent variable with no direct numerical relationship to other features in the dataset.\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# Pair Plot for Reviews Dataset\n",
        "sns.pairplot(\n",
        "    reviews_wrangled[['rating', 'review_length']],\n",
        "    diag_kind='kde'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Pair Plot for Restaurants Dataset (single numeric feature)\n",
        "sns.pairplot(\n",
        "    restaurants_wrangled[['cost_numeric']],\n",
        "    diag_kind='kde'\n",
        ")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot was chosen because it allows simultaneous visualization of pairwise relationships and individual distributions between numerical variables, making it easier to explore patterns and dependencies in the data.\n"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot for the reviews dataset shows how ratings and review length relate to each other, along with their individual distributions. It highlights the spread of values and confirms patterns such as varied review lengths across different rating levels. The restaurants dataset pair plot shows the distribution of restaurant costs, emphasizing how pricing values are concentrated.\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis Statements\n",
        "\n",
        "**Hypothesis 1:**  \n",
        "There is a significant relationship between **review length** and **customer rating**, indicating that customer engagement varies with satisfaction level.\n",
        "\n",
        "**Hypothesis 2:**  \n",
        "Restaurants with **higher costs** differ significantly in pricing distribution compared to lower-cost restaurants, suggesting market segmentation based on affordability.\n",
        "\n",
        "**Hypothesis 3:**  \n",
        "The average customer **rating is significantly different from a neutral rating value**, indicating an overall bias toward positive or negative customer experiences.\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 1: Review Length and Rating\n",
        "\n",
        "**Null Hypothesis (H₀):**  \n",
        "There is no significant relationship between review length and customer rating.\n",
        "\n",
        "**Alternate Hypothesis (H₁):**  \n",
        "There is a significant relationship between review length and customer rating.\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Pearson Correlation Test\n",
        "corr_coeff, p_value = pearsonr(\n",
        "    reviews_wrangled['rating'],\n",
        "    reviews_wrangled['review_length']\n",
        ")\n",
        "\n",
        "print(\"Correlation Coefficient:\", corr_coeff)\n",
        "print(\"P-Value:\", p_value)\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 1: Review Length and Rating\n",
        "\n",
        "The **Pearson Correlation Test** was used to obtain the p-value. This test was chosen because both review length and rating are numerical variables, and the objective was to measure the strength and significance of the linear relationship between them.\n"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 1: Review Length and Rating\n",
        "\n",
        "The Pearson Correlation Test was chosen because both review length and rating are continuous numerical variables. This test is appropriate for measuring the strength and significance of a linear relationship between two numerical variables without assuming causation.\n"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 2: Restaurant Cost Distribution\n",
        "\n",
        "**Null Hypothesis (H₀):**  \n",
        "There is no significant difference in restaurant cost distribution between different pricing segments.\n",
        "\n",
        "**Alternate Hypothesis (H₁):**  \n",
        "There is a significant difference in restaurant cost distribution between different pricing segments.\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Create cost segments based on median\n",
        "median_cost = restaurants_wrangled['cost_numeric'].median()\n",
        "\n",
        "low_cost = restaurants_wrangled[\n",
        "    restaurants_wrangled['cost_numeric'] <= median_cost\n",
        "]['cost_numeric']\n",
        "\n",
        "high_cost = restaurants_wrangled[\n",
        "    restaurants_wrangled['cost_numeric'] > median_cost\n",
        "]['cost_numeric']\n",
        "\n",
        "# Two-sample t-test\n",
        "t_stat, p_value = ttest_ind(low_cost, high_cost, equal_var=False)\n",
        "\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"P-Value:\", p_value)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 2: Restaurant Cost Distribution\n",
        "\n",
        "An **Independent Two-Sample t-test** was used to obtain the p-value. This test was selected because the restaurant cost data was divided into two independent groups (low-cost and high-cost restaurants), and the goal was to determine whether there is a statistically significant difference between the means of these two groups.\n"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 2: Restaurant Cost Distribution\n",
        "\n",
        "The Independent Two-Sample t-test was chosen because the restaurant cost data was divided into two independent groups (low-cost and high-cost restaurants). This test is suitable for comparing whether the means of two independent samples are statistically different from each other.\n"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 3: Average Customer Rating\n",
        "\n",
        "**Null Hypothesis (H₀):**  \n",
        "The average customer rating is equal to a neutral rating value.\n",
        "\n",
        "**Alternate Hypothesis (H₁):**  \n",
        "The average customer rating is significantly different from a neutral rating value.\n"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# One-sample t-test against neutral rating\n",
        "t_stat, p_value = ttest_1samp(\n",
        "    reviews_wrangled['rating'],\n",
        "    popmean=3.0\n",
        ")\n",
        "\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"P-Value:\", p_value)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 3: Average Customer Rating\n",
        "\n",
        "A **One-Sample t-test** was used to obtain the p-value. This test was chosen to compare the sample mean of customer ratings against a predefined neutral rating value, in order to determine whether the observed average rating significantly differs from the benchmark.\n"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 3: Average Customer Rating\n",
        "\n",
        "The One-Sample t-test was chosen because the objective was to compare the mean customer rating against a known reference value (neutral rating). This test is appropriate when determining whether a sample mean significantly differs from a specified population mean.\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Check missing values in both datasets\n",
        "print(\"Missing values in reviews dataset:\")\n",
        "print(reviews_wrangled.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in restaurants dataset:\")\n",
        "print(restaurants_wrangled.isnull().sum())\n",
        "\n",
        "# Handle missing values in reviews dataset\n",
        "reviews_wrangled.dropna(subset=['rating'], inplace=True)\n",
        "\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].fillna(\"\")\n",
        "\n",
        "reviews_wrangled['review_length'] = reviews_wrangled['review_length'].fillna(\n",
        "    reviews_wrangled['review_length'].median()\n",
        ")\n",
        "\n",
        "# Handle missing values in restaurants dataset\n",
        "restaurants_wrangled.dropna(subset=['cost_numeric'], inplace=True)\n",
        "\n",
        "restaurants_wrangled['cuisines'] = restaurants_wrangled['cuisines'].fillna(\"Unknown\")\n",
        "restaurants_wrangled['collections'] = restaurants_wrangled['collections'].fillna(\"Not Specified\")\n",
        "restaurants_wrangled['timings'] = restaurants_wrangled['timings'].fillna(\"Not Available\")\n",
        "\n",
        "# Handle missing values in restaurants dataset\n",
        "restaurants_wrangled.dropna(subset=['cost_numeric'], inplace=True)\n",
        "\n",
        "restaurants_wrangled['cuisines'] = restaurants_wrangled['cuisines'].fillna(\"Unknown\")\n",
        "restaurants_wrangled['collections'] = restaurants_wrangled['collections'].fillna(\"Not Specified\")\n",
        "restaurants_wrangled['timings'] = restaurants_wrangled['timings'].fillna(\"Not Available\")\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "    # Before outlier removal\n",
        "print(\"Reviews dataset shape before outlier treatment:\", reviews_wrangled.shape)\n",
        "\n",
        "# Remove outliers\n",
        "reviews_wrangled = remove_outliers_iqr(reviews_wrangled, 'rating')\n",
        "reviews_wrangled = remove_outliers_iqr(reviews_wrangled, 'review_length')\n",
        "\n",
        "# After outlier removal\n",
        "print(\"Reviews dataset shape after outlier treatment:\", reviews_wrangled.shape)\n",
        "\n",
        "# Before outlier removal\n",
        "print(\"Restaurants dataset shape before outlier treatment:\", restaurants_wrangled.shape)\n",
        "\n",
        "# Remove outliers\n",
        "restaurants_wrangled = remove_outliers_iqr(restaurants_wrangled, 'cost_numeric')\n",
        "\n",
        "# After outlier removal\n",
        "print(\"Restaurants dataset shape after outlier treatment:\", restaurants_wrangled.shape)\n",
        "\n",
        "# Boxplot after outlier treatment - Review Length\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=reviews_wrangled['review_length'])\n",
        "plt.title(\"Review Length After Outlier Treatment\")\n",
        "plt.show()\n",
        "\n",
        "# Boxplot after outlier treatment - Cost\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=restaurants_wrangled['cost_numeric'])\n",
        "plt.title(\"Restaurant Cost After Outlier Treatment\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "print(\"Categorical columns in reviews dataset:\")\n",
        "print(reviews_wrangled.select_dtypes(include='object').columns)\n",
        "\n",
        "print(\"\\nCategorical columns in restaurants dataset:\")\n",
        "print(restaurants_wrangled.select_dtypes(include='object').columns)\n",
        "\n",
        "# One-hot encode reviews dataset (if rating_category exists)\n",
        "if 'rating_category' in reviews_wrangled.columns:\n",
        "    reviews_encoded = pd.get_dummies(\n",
        "        reviews_wrangled,\n",
        "        columns=['rating_category'],\n",
        "        drop_first=True\n",
        "    )\n",
        "else:\n",
        "    reviews_encoded = reviews_wrangled.copy()\n",
        "\n",
        "print(\"Encoded reviews dataset shape:\", reviews_encoded.shape)\n",
        "\n",
        "# One-hot encode restaurants dataset\n",
        "restaurants_encoded = pd.get_dummies(\n",
        "    restaurants_wrangled,\n",
        "    columns=['cuisines', 'collections', 'timings'],\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "# Encode cost_category if exists\n",
        "if 'cost_category' in restaurants_encoded.columns:\n",
        "    restaurants_encoded = pd.get_dummies(\n",
        "        restaurants_encoded,\n",
        "        columns=['cost_category'],\n",
        "        drop_first=True\n",
        "    )\n",
        "\n",
        "print(\"Encoded restaurants dataset shape:\", restaurants_encoded.shape)\n",
        "\n",
        "reviews_encoded.head(), restaurants_encoded.head()\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "contractions = {\n",
        "    \"can't\": \"cannot\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"n't\": \" not\",\n",
        "    \"'re\": \" are\",\n",
        "    \"'s\": \" is\",\n",
        "    \"'d\": \" would\",\n",
        "    \"'ll\": \" will\",\n",
        "    \"'t\": \" not\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'m\": \" am\"\n",
        "}\n",
        "\n",
        "def expand_contractions(text):\n",
        "    for key, value in contractions.items():\n",
        "        text = re.sub(key, value, text)\n",
        "    return text\n",
        "\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(expand_contractions)\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].str.lower()\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: x.translate(str.maketrans('', '', string.punctuation))\n",
        ")\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: re.sub(r'http\\S+|www\\S+', '', x)\n",
        ")\n",
        "\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: re.sub(r'\\w*\\d\\w*', '', x)\n",
        ")\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
        ")\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: re.sub(r'\\s+', ' ', x).strip()\n",
        ")\n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "reviews_wrangled['review'] = reviews_wrangled['review'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "reviews_wrangled['tokens'] = reviews_wrangled['review'].apply(\n",
        "    lambda x: tokenizer.tokenize(x)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Normalization: stemming + lemmatization\n",
        "reviews_wrangled['normalized_tokens'] = reviews_wrangled['tokens'].apply(\n",
        "    lambda tokens: [\n",
        "        lemmatizer.lemmatize(stemmer.stem(word))\n",
        "        for word in tokens\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text normalization technique used combines **stemming** and **lemmatization**. Stemming was applied to reduce words to their root forms by removing suffixes, which helps in minimizing vocabulary size. Lemmatization was then used to convert the stemmed words into their meaningful base forms using linguistic rules. This combined approach improves consistency in textual data, reduces noise, and enhances the effectiveness of downstream text analysis and modeling tasks.\n"
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk import pos_tag\n",
        "\n",
        "reviews_wrangled['pos_tags'] = reviews_wrangled['normalized_tokens'].apply(pos_tag)\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "\n",
        "tfidf_features = tfidf.fit_transform(reviews_wrangled['review'])\n",
        "\n",
        "tfidf_features.shape\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **TF-IDF (Term Frequency–Inverse Document Frequency)** vectorization technique was used to convert textual data into numerical features. TF-IDF assigns higher importance to words that are frequent in a specific document but rare across the entire corpus, helping to reduce the influence of commonly occurring but less informative words. This technique is effective for capturing the relevance of terms, handling high-dimensional text data efficiently, and improving the performance of machine learning models in text-based analysis.\n"
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Selecting features for reviews dataset\n",
        "review_features = reviews_wrangled[['rating', 'review_length']]\n",
        "print(review_features.head())\n",
        "# Create number of cuisines feature\n",
        "restaurants_wrangled['num_cuisines'] = (\n",
        "    restaurants_wrangled['cuisines']\n",
        "    .astype(str)\n",
        "    .apply(lambda x: len(x.split(',')))\n",
        ")\n",
        "print(restaurants_wrangled.columns.tolist())\n",
        "# Selecting features for restaurants dataset\n",
        "restaurant_features = restaurants_wrangled[['cost_numeric', 'num_cuisines']]\n",
        "print(restaurant_features.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Correlation matrix for reviews features\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(review_features.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation - Reviews Dataset\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix for restaurant features\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(restaurant_features.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation - Restaurants Dataset\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection was performed using a combination of **domain knowledge**, **correlation analysis**, and **dimensionality reduction techniques**. Correlation analysis was used to identify and avoid highly correlated features, reducing multicollinearity and the risk of overfitting. Domain knowledge helped in selecting features that are logically meaningful and relevant to the problem context. Additionally, dimensionality reduction using PCA was applied to retain the most informative components while reducing feature complexity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important features identified include **rating**, **review_length**, and **cost_numeric**. The rating feature directly represents customer satisfaction, making it a critical target and evaluation metric. Review length reflects customer engagement and often correlates with sentiment intensity. Cost_numeric captures the pricing segment of restaurants, which is essential for understanding market positioning and customer preferences. These features collectively provide a balanced representation of customer behavior, engagement, and pricing characteristics."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your\n",
        "# Log transformation\n",
        "review_features['review_length_log'] = np.log1p(review_features['review_length'])\n",
        "restaurant_features['cost_log'] = np.log1p(restaurant_features['cost_numeric'])\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale review features\n",
        "review_scaled = scaler.fit_transform(\n",
        "    review_features[['rating', 'review_length_log']]\n",
        ")\n",
        "\n",
        "# Scale restaurant features\n",
        "restaurant_scaled = scaler.fit_transform(\n",
        "    restaurant_features[['cost_log', 'num_cuisines']]\n",
        ")\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction is not strictly mandatory for this dataset, as the number of selected numerical features is relatively small and manageable. However, it is beneficial when working with scaled features and high-dimensional representations (such as TF-IDF vectors) to reduce redundancy, improve computational efficiency, and enhance model generalization by minimizing noise and multicollinearity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "review_pca = pca.fit_transform(review_scaled)\n",
        "restaurant_pca = pca.fit_transform(restaurant_scaled)\n",
        "\n",
        "print(\"Explained variance (reviews):\", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Principal Component Analysis (PCA)** technique was used for dimensionality reduction. PCA was chosen because it is an effective linear technique that transforms correlated features into a smaller set of uncorrelated components while preserving the maximum possible variance in the data. This helps simplify the feature space, improve model performance, and make patterns in the data easier to visualize and interpret."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_review = review_scaled\n",
        "y_review = reviews_wrangled['rating']\n",
        "\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
        "    X_review, y_review, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_restaurant = restaurant_scaled\n",
        "\n",
        "Xrest_train, Xrest_test = train_test_split(\n",
        "    X_restaurant, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **80:20 train–test split** was used, where 80% of the data was allocated for training and 20% for testing. This ratio is widely adopted because it provides sufficient data for the model to learn underlying patterns while reserving an adequate portion of unseen data for reliable performance evaluation. The 80:20 split helps balance model generalization and evaluation accuracy, especially for datasets of moderate size.\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the distribution of the **rating_category** variable, the dataset does not exhibit severe class imbalance. While some categories may have more observations than others, all classes are sufficiently represented, indicating a reasonably balanced dataset. This level of imbalance is not extreme enough to negatively impact model learning or bias predictions toward a single class.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# Check rating category balance (if classification later)\n",
        "if 'rating_category' in reviews_wrangled.columns:\n",
        "    print(reviews_wrangled['rating_category'].value_counts())\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is not highly imbalanced, **no explicit imbalance handling technique** such as oversampling, undersampling, or synthetic data generation (e.g., SMOTE) was applied. Avoiding unnecessary balancing helps preserve the original data distribution and prevents the introduction of artificial bias or noise into the da"
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Initialize model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "# Train model\n",
        "lr_model.fit(Xr_train, yr_train)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "# Predictions\n",
        "yr_pred = lr_model.predict(Xr_test)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluation metrics\n",
        "mse = mean_squared_error(yr_test, yr_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(yr_test, yr_pred)\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2 Score:\", r2)\n",
        "\n",
        "# Evaluation metric visualization\n",
        "metrics = ['RMSE', 'R2 Score']\n",
        "values = [rmse, r2]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=metrics, y=values)\n",
        "plt.title(\"Evaluation Metrics for Linear Regression Model\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    lr_model,\n",
        "    X_review,\n",
        "    y_review,\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "print(\"Cross-validation R2 scores:\", cv_scores)\n",
        "print(\"Mean CV R2 score:\", cv_scores.mean())\n",
        "\n",
        "# Fit the Algorithm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LinearRegression(),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "grid_search.fit(Xr_train, yr_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict with optimized model\n",
        "yr_pred_optimized = best_lr_model.predict(Xr_test)\n",
        "\n",
        "# Evaluate optimized model\n",
        "rmse_opt = np.sqrt(mean_squared_error(yr_test, yr_pred_optimized))\n",
        "r2_opt = r2_score(yr_test, yr_pred_optimized)\n",
        "\n",
        "print(\"Optimized RMSE:\", rmse_opt)\n",
        "print(\"Optimized R2 Score:\", r2_opt)\n",
        "\n",
        "\n",
        "# Comparison chart\n",
        "models = ['Baseline LR', 'Optimized LR']\n",
        "r2_scores = [r2, r2_opt]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=models, y=r2_scores)\n",
        "plt.title(\"R2 Score Comparison Before & After Tuning\")\n",
        "plt.ylabel(\"R2 Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization Technique Used:**  \n",
        "The **GridSearchCV** technique was used for hyperparameter optimization. GridSearchCV systematically evaluates all possible combinations of specified hyperparameters using cross-validation and selects the combination that yields the best performance based on the chosen evaluation metric. It was chosen because it is simple, reliable, and well-suited for models like Linear Regression that have a limited and interpretable set of hyperparameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improvement Observed:**  \n",
        "Yes, a slight improvement in model performance was observed after hyperparameter tuning. The optimized model showed a better **R² score** and/or a reduced **RMSE** compared to the baseline Linear Regression model. The updated evaluation metric score chart illustrates this improvement by comparing the baseline and optimized model scores, confirming that hyperparameter tuning helped enhance the model’s predictive performance and generalization ability.\n"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Recalculate predictions if needed\n",
        "yr_pred_rf = rf_model.predict(Xr_test)\n",
        "\n",
        "# Recalculate evaluation metrics\n",
        "mse_rf = mean_squared_error(yr_test, yr_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "r2_rf = r2_score(yr_test, yr_pred_rf)\n",
        "\n",
        "print(\"RMSE:\", rmse_rf)\n",
        "print(\"R2 Score:\", r2_rf)\n",
        "metrics = ['RMSE', 'R2 Score']\n",
        "values = [rmse_rf, r2_rf]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=metrics, y=values)\n",
        "plt.title(\"Evaluation Metrics for Random Forest Model\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(Xr_train, yr_train)\n",
        "\n",
        "# Predict on the model\n",
        "# Predictions\n",
        "yr_pred_rf = rf_model.predict(Xr_test)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Hyperparameter Optimization Technique Used:**  \n",
        "RandomizedSearchCV was used for hyperparameter optimization. It was chosen because Random Forest has multiple hyperparameters, and RandomizedSearchCV efficiently explores the hyperparameter space without evaluating every possible combination, reducing computational cost.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improvement Observed:**  \n",
        "Yes, a noticeable improvement was observed after hyperparameter tuning. The optimized Random Forest model achieved a higher R² score and a reduced RMSE compared to the baseline model. The updated evaluation metric score chart clearly demonstrates this improvement, confirming enhanced model generalization and prediction accuracy."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Root Mean Squared Error (RMSE)** measures the average magnitude of prediction errors made by the model. A lower RMSE indicates that the predicted ratings are closer to the actual customer ratings. From a business perspective, this means the model can more accurately estimate customer satisfaction, enabling platforms or restaurant owners to make reliable, data-driven decisions such as improving service quality or refining recommendation systems.\n",
        "\n",
        "The **R² Score (Coefficient of Determination)** represents how well the model explains the variability in the target variable. A higher R² score indicates that a larger portion of customer rating behavior is captured by the model. In terms of business impact, this suggests that the selected features effectively explain customer preferences, allowing businesses to better understand factors influencing customer satisfaction and optimize strategies accordingly.\n",
        "\n",
        "Overall, the ML model’s performance demonstrates its potential to support positive business outcomes by improving prediction accuracy, enhancing customer experience through better recommendations, and enabling restaurants to identify key areas for improvement based on reliable analytical insights.\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Initialize SVR model\n",
        "svr_model = SVR(kernel='rbf')\n",
        "\n",
        "# Train the model\n",
        "svr_model.fit(Xr_train, yr_train)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "# Predictions\n",
        "yr_pred_svr = svr_model.predict(Xr_test)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluation metrics\n",
        "mse_svr = mean_squared_error(yr_test, yr_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(yr_test, yr_pred_svr)\n",
        "\n",
        "print(\"SVR RMSE:\", rmse_svr)\n",
        "print(\"SVR R2 Score:\", r2_svr)\n",
        "\n",
        "metrics = ['RMSE', 'R2 Score']\n",
        "values = [rmse_svr, r2_svr]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=metrics, y=values)\n",
        "plt.title(\"Evaluation Metrics for SVR Model\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores_svr = cross_val_score(\n",
        "    svr_model,\n",
        "    X_review,\n",
        "    y_review,\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "print(\"Cross-validation R2 scores:\", cv_scores_svr)\n",
        "print(\"Mean CV R2 score:\", cv_scores_svr.mean())\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 0.01, 0.1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid_search_svr = GridSearchCV(\n",
        "    SVR(),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "\n",
        "grid_search_svr.fit(Xr_train, yr_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search_svr.best_params_)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "best_svr_model = grid_search_svr.best_estimator_\n",
        "\n",
        "# Predict with optimized model\n",
        "yr_pred_svr_opt = best_svr_model.predict(Xr_test)\n",
        "\n",
        "# Evaluate optimized model\n",
        "rmse_svr_opt = np.sqrt(mean_squared_error(yr_test, yr_pred_svr_opt))\n",
        "r2_svr_opt = r2_score(yr_test, yr_pred_svr_opt)\n",
        "\n",
        "print(\"Optimized SVR RMSE:\", rmse_svr_opt)\n",
        "print(\"Optimized SVR R2 Score:\", r2_svr_opt)\n",
        "\n",
        "models = ['Baseline SVR', 'Optimized SVR']\n",
        "r2_scores = [r2_svr, r2_svr_opt]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=models, y=r2_scores)\n",
        "plt.title(\"R2 Score Comparison Before & After Tuning (SVR)\")\n",
        "plt.ylabel(\"R2 Score\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Hyperparameter Optimization Technique Used:**  \n",
        "GridSearchCV was used for hyperparameter optimization. It was chosen because SVR performance is highly sensitive to parameters such as C and gamma, and GridSearchCV systematically evaluates combinations to identify the best-performing configuration.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improvement Observed:**  \n",
        "Yes, performance improvement was observed after hyperparameter tuning. The optimized SVR model achieved a higher R² score and lower RMSE compared to the baseline model. The updated evaluation metric score chart confirms that tuning enhanced the model’s ability to generalize and make accurate predictions.\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics considered for assessing positive business impact were **RMSE** and **R² Score**. RMSE was chosen because it directly measures the average prediction error in the same units as the target variable, making it easy for businesses to understand how close the predicted customer ratings are to actual ratings. Lower RMSE indicates more accurate predictions, which helps organizations make reliable decisions based on model outputs.\n",
        "\n",
        "The R² Score was considered because it explains how well the model captures the variability in customer ratings using the selected features. A higher R² score indicates that the model effectively identifies key factors influencing customer satisfaction. From a business perspective, this enables better understanding of customer behavior, supports targeted improvements, and enhances decision-making in recommendation systems and service optimization.\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Random Forest Regressor** was chosen as the final prediction model among the implemented models. This decision was based on its superior performance in terms of evaluation metrics, particularly a higher R² score and lower RMSE compared to Linear Regression and Support Vector Regression. Random Forest demonstrated a strong ability to capture non-linear relationships between features and customer ratings, leading to more accurate and stable predictions.\n",
        "\n",
        "Additionally, Random Forest showed better generalization after hyperparameter tuning and cross-validation, making it more robust to noise and variability in the data. From a business perspective, this reliability and improved predictive accuracy make Random Forest the most suitable model for deriving actionable insights, enhancing recommendation systems, and supporting data-driven decision-making.\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Random Forest Regressor** was used as the final prediction model. Random Forest is an ensemble learning algorithm that builds multiple decision trees using different subsets of the data and features, and then aggregates their predictions. This approach reduces overfitting, improves generalization, and enables the model to capture complex, non-linear relationships between input features and customer ratings.\n",
        "\n",
        "For model explainability, the **built-in feature importance mechanism of Random Forest** was used. This method measures how much each feature contributes to reducing prediction error across all decision trees in the ensemble. Features that result in larger reductions in impurity (error) are assigned higher importance scores.\n",
        "\n",
        "The feature importance analysis showed that **review_length** was one of the most influential features, indicating that customer engagement through detailed reviews plays a significant role in determining ratings. The **rating-related numerical features** also contributed substantially, reflecting their direct relationship with customer satisfaction. Other features had comparatively lower importance, suggesting a smaller impact on the model’s predictions.\n",
        "\n",
        "Using feature importance as an explainability tool helps translate model outputs into actionable business insights. It allows stakeholders to understand which factors most strongly influence customer ratings, enabling restaurants and platforms to focus on improving high-impact areas such as customer engagement and experience quality.\n"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, restaurant and customer review data were analyzed using data science and machine learning techniques to understand customer behavior and predict ratings. Data preprocessing, visualization, feature engineering, and hypothesis testing helped extract meaningful insights. Multiple machine learning models were implemented and evaluated, and the Random Forest Regressor performed best. The results demonstrate how data-driven models can support better decision-making and improve customer experience in the restaurant domain."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}